{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO2V39enXj+KoJWpoJuvFen",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MenaVhs/DLC-Modelo/blob/main/Training_DLC_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1) Colab Environment Configuration\n",
        "\n",
        "On the upper left in Google Colab select \"Runtime\", \"change Runtime type\", select \"Python3\" and \"GPU\" as hardware accelerator and click \"save\".\n",
        "\n",
        "\n",
        "Next, install deeplabcut, and at the bottom of the output restart Runtime (this may take a few minutes)."
      ],
      "metadata": {
        "id": "QpqJ6iRcniUY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install deeplabcut"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_w0UwzGnwtd",
        "outputId": "16c7d993-e683-4f68-c528-65e7c8468929"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting deeplabcut\n",
            "  Downloading deeplabcut-2.3.5-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dlclibrary (from deeplabcut)\n",
            "  Downloading dlclibrary-0.0.4-py3-none-any.whl (15 kB)\n",
            "Collecting filterpy>=1.4.4 (from deeplabcut)\n",
            "  Downloading filterpy-1.4.5.zip (177 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.0/178.0 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ruamel.yaml>=0.15.0 (from deeplabcut)\n",
            "  Downloading ruamel.yaml-0.17.32-py3-none-any.whl (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.2/112.2 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: imgaug>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from deeplabcut) (0.4.0)\n",
            "Requirement already satisfied: imageio-ffmpeg in /usr/local/lib/python3.10/dist-packages (from deeplabcut) (0.4.8)\n",
            "Requirement already satisfied: numba>=0.54 in /usr/local/lib/python3.10/dist-packages (from deeplabcut) (0.56.4)\n",
            "Requirement already satisfied: matplotlib>=3.3 in /usr/local/lib/python3.10/dist-packages (from deeplabcut) (3.7.1)\n",
            "Requirement already satisfied: networkx>=2.6 in /usr/local/lib/python3.10/dist-packages (from deeplabcut) (3.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from deeplabcut) (1.23.5)\n",
            "Requirement already satisfied: pandas!=1.5.0,>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from deeplabcut) (1.5.3)\n",
            "Requirement already satisfied: scikit-image>=0.17 in /usr/local/lib/python3.10/dist-packages (from deeplabcut) (0.19.3)\n",
            "Requirement already satisfied: scikit-learn>=1.0 in /usr/local/lib/python3.10/dist-packages (from deeplabcut) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.4 in /usr/local/lib/python3.10/dist-packages (from deeplabcut) (1.10.1)\n",
            "Requirement already satisfied: statsmodels>=0.11 in /usr/local/lib/python3.10/dist-packages (from deeplabcut) (0.14.0)\n",
            "Requirement already satisfied: tables>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from deeplabcut) (3.8.0)\n",
            "Collecting torch<=1.12 (from deeplabcut)\n",
            "  Downloading torch-1.12.0-cp310-cp310-manylinux1_x86_64.whl (776.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.3/776.3 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorpack>=0.11 (from deeplabcut)\n",
            "  Downloading tensorpack-0.11-py2.py3-none-any.whl (296 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.3/296.3 kB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tf-slim>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from deeplabcut) (1.1.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from deeplabcut) (4.66.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from deeplabcut) (6.0.1)\n",
            "Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.10/dist-packages (from deeplabcut) (9.4.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from imgaug>=0.4.0->deeplabcut) (1.16.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from imgaug>=0.4.0->deeplabcut) (4.8.0.76)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (from imgaug>=0.4.0->deeplabcut) (2.31.1)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.10/dist-packages (from imgaug>=0.4.0->deeplabcut) (2.0.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->deeplabcut) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->deeplabcut) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->deeplabcut) (4.42.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->deeplabcut) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->deeplabcut) (23.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->deeplabcut) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->deeplabcut) (2.8.2)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.54->deeplabcut) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba>=0.54->deeplabcut) (67.7.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas!=1.5.0,>=1.0.1->deeplabcut) (2023.3)\n",
            "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml>=0.15.0->deeplabcut)\n",
            "  Downloading ruamel.yaml.clib-0.2.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (485 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.6/485.6 kB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.17->deeplabcut) (2023.8.12)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.17->deeplabcut) (1.4.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0->deeplabcut) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0->deeplabcut) (3.2.0)\n",
            "Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.11->deeplabcut) (0.5.3)\n",
            "Requirement already satisfied: cython>=0.29.21 in /usr/local/lib/python3.10/dist-packages (from tables>=3.7.0->deeplabcut) (0.29.36)\n",
            "Requirement already satisfied: numexpr>=2.6.2 in /usr/local/lib/python3.10/dist-packages (from tables>=3.7.0->deeplabcut) (2.8.5)\n",
            "Requirement already satisfied: blosc2~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from tables>=3.7.0->deeplabcut) (2.0.0)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from tables>=3.7.0->deeplabcut) (9.0.0)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.10/dist-packages (from tensorpack>=0.11->deeplabcut) (2.3.0)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from tensorpack>=0.11->deeplabcut) (0.9.0)\n",
            "Requirement already satisfied: msgpack>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from tensorpack>=0.11->deeplabcut) (1.0.5)\n",
            "Collecting msgpack-numpy>=0.4.4.2 (from tensorpack>=0.11->deeplabcut)\n",
            "  Downloading msgpack_numpy-0.4.8-py2.py3-none-any.whl (6.9 kB)\n",
            "Requirement already satisfied: pyzmq>=16 in /usr/local/lib/python3.10/dist-packages (from tensorpack>=0.11->deeplabcut) (23.2.1)\n",
            "Requirement already satisfied: psutil>=5 in /usr/local/lib/python3.10/dist-packages (from tensorpack>=0.11->deeplabcut) (5.9.5)\n",
            "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from tf-slim>=1.1.0->deeplabcut) (1.4.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch<=1.12->deeplabcut) (4.7.1)\n",
            "Collecting huggingface-hub (from dlclibrary->deeplabcut)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->dlclibrary->deeplabcut) (3.12.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->dlclibrary->deeplabcut) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->dlclibrary->deeplabcut) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->dlclibrary->deeplabcut) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->dlclibrary->deeplabcut) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->dlclibrary->deeplabcut) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->dlclibrary->deeplabcut) (2023.7.22)\n",
            "Building wheels for collected packages: filterpy\n",
            "  Building wheel for filterpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for filterpy: filename=filterpy-1.4.5-py3-none-any.whl size=110459 sha256=7066c4d15bdd22a68537a62de12db4facc41d869f377c707419a68d44f70ecec\n",
            "  Stored in directory: /root/.cache/pip/wheels/0f/0c/ea/218f266af4ad626897562199fbbcba521b8497303200186102\n",
            "Successfully built filterpy\n",
            "Installing collected packages: torch, ruamel.yaml.clib, msgpack-numpy, tensorpack, ruamel.yaml, huggingface-hub, filterpy, dlclibrary, deeplabcut\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.0.1+cu118\n",
            "    Uninstalling torch-2.0.1+cu118:\n",
            "      Successfully uninstalled torch-2.0.1+cu118\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.0.2+cu118 requires torch==2.0.1, but you have torch 1.12.0 which is incompatible.\n",
            "torchdata 0.6.1 requires torch==2.0.1, but you have torch 1.12.0 which is incompatible.\n",
            "torchtext 0.15.2 requires torch==2.0.1, but you have torch 1.12.0 which is incompatible.\n",
            "torchvision 0.15.2+cu118 requires torch==2.0.1, but you have torch 1.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed deeplabcut-2.3.5 dlclibrary-0.0.4 filterpy-1.4.5 huggingface-hub-0.16.4 msgpack-numpy-0.4.8 ruamel.yaml-0.17.32 ruamel.yaml.clib-0.2.7 tensorpack-0.11 torch-1.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After restarting runtime, select tensorflow version < 2:"
      ],
      "metadata": {
        "id": "HxI3fgfqn7A8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorflow_version 2.x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zo6FRuGn85Z",
        "outputId": "2ecef87b-613e-4a2c-c199-3fdda4e19d8e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "And make sure to import DeeplabCut in light mode, as cloud computing does not allow to use GUIs:"
      ],
      "metadata": {
        "id": "dtNEarIcn-1t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"DLClight\"]=\"True\""
      ],
      "metadata": {
        "id": "sA6Rc573oBNZ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install matplotlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5x5_y7-goZma",
        "outputId": "857ff50b-d6a7-4311-fdd6-c2ccb0a4d34f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.42.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import deeplabcut"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZprPoXurMvj",
        "outputId": "b9a92b53-864e-47dd-e340-e2bc4659553c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading DLC 2.3.5...\n",
            "DLC loaded in light mode; you cannot use any GUI (labeling, relabeling and standalone GUI)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now you have to mount a valid google drive account to google colab. Follow the link provided to log in to google drive and copy paste the authentication code below: ⚗"
      ],
      "metadata": {
        "id": "JbpqiAiDrTkA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qerBEWjmrYgu",
        "outputId": "61d16bfa-9ee9-4d9b-ff7f-691798d9c08f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Now the important part: Because we started the project in our local machine and then exported it to the cloud, all paths are messed up and need to be updated.\n",
        "\n",
        "After uploading your DLC project folder to google drive copy the project folder name to reconstruct the new project_path:"
      ],
      "metadata": {
        "id": "1TcvksXar57r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "!ls \"/content/drive/MyDrive\"\n",
        "ProjectFolderName = 'DLC_experimentos/Shoenfield-Mena-2023-08-31'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ov2oA4sr6wi",
        "outputId": "4336bc7a-0b40-4171-bf7a-769f4f74172d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'Apreciadas <3'\n",
            " CEICAH\n",
            " Classroom\n",
            "'Colab Notebooks'\n",
            " ConstanciaVariacionR1-Mena-2023-02-23\n",
            "'Cursos de finanzas.mp3'\n",
            " CV_English.pdf\n",
            "'CV_Español (1).pdf'\n",
            " CV_Español.pdf\n",
            " CVs\n",
            " DLC_experimentos\n",
            " documentos\n",
            " EGEL\n",
            "'El Libro que el SAT No Quiere que leas Todo lo que NUNCA te enseñaron de Impuestos (Spanish Edition).azw3'\n",
            "'Filtros activos Actividad.pdf'\n",
            " GAGJ970902MDFRRM02.pdf\n",
            " Grupo2R4S15TRIMDLC_resnet50_CVFeb26shuffle1_213000_filtered_labeled.mp4\n",
            "'identificador de Plátano.docx'\n",
            " IELTS_p10-11_reading.gdoc\n",
            " JimenaGarcía.pdf\n",
            " JuanaSoledadGordillo.pdf\n",
            " LANIA\n",
            "'Libro Crear o Morir Andrés Oppenheimer.pdf'\n",
            " Libros\n",
            " Method.gdoc\n",
            "'Notas de GoogleColab y DLC'\n",
            " NuestroUniverso\n",
            " SAT\n",
            "'Sobre finanzas'\n",
            "'Untitled document.gdoc'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "project_path = '/content/drive/MyDrive/'+ ProjectFolderName\n",
        "videofile_path = ['/content/drive/MyDrive/'+ProjectFolderName+'/videos/']\n",
        "path_config_file = '/content/drive/MyDrive/'+ProjectFolderName+'/config.yaml'\n",
        "\n",
        "print('NEW project_path: ' + project_path)\n",
        "print('NEW videofile_path: ' + videofile_path[0])\n",
        "print('NEW path_config_file: ' + path_config_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vasMsE-RsJGP",
        "outputId": "a6d64b4f-38b3-4063-c288-ec254e925e96"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW project_path: /content/drive/MyDrive/DLC_experimentos/Shoenfield-Mena-2023-08-31\n",
            "NEW videofile_path: /content/drive/MyDrive/DLC_experimentos/Shoenfield-Mena-2023-08-31/videos/\n",
            "NEW path_config_file: /content/drive/MyDrive/DLC_experimentos/Shoenfield-Mena-2023-08-31/config.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Enter your new project_path below\n",
        "!ls '/content/drive/MyDrive/DLC_experimentos/Shoenfield-Mena-2023-08-31'"
      ],
      "metadata": {
        "id": "doL_tTbysTBB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10196faf-7ba0-4310-f8dc-4229107a6a2e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "config.yaml  dlc-models  labeled-data  training-datasets  videos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "If you see the content of your DLC project listed in the output above (specially the config.yaml file), copy the new project_path to your project and paste it in the config.yaml file in google drive."
      ],
      "metadata": {
        "id": "1TIW8uossz0F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2) Training New DLC Model\n",
        "Create a training dataset from your labeled frames to train your model:\n"
      ],
      "metadata": {
        "id": "7b2FReXls4Lo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "deeplabcut.create_training_dataset(path_config_file, net_type='resnet_101', augmenter_type='imgaug')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rqdab8ENszpD",
        "outputId": "e301c75f-f02c-4523-b5fd-2142961153df"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading a ImageNet-pretrained model from http://download.tensorflow.org/models/resnet_v1_101_2016_08_28.tar.gz....\n",
            "The training dataset is successfully created. Use the function 'train_network' to start training. Happy training!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0.95,\n",
              "  1,\n",
              "  (array([26, 35, 59, 28, 11,  2, 34, 58, 40, 22,  4, 10, 30, 41, 33, 43, 49,\n",
              "           7, 14, 32, 50, 29, 42, 54, 18, 56, 27, 15,  5, 31, 16, 51, 20, 52,\n",
              "           8, 13, 25, 37, 17, 45, 48, 57, 38,  1, 12, 46, 24,  6, 23, 36, 21,\n",
              "          19,  9, 39, 55,  3,  0]),\n",
              "   array([53, 47, 44])))]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You are now officially ready to start training!\n",
        "Change displayiters to have more or less printed feedback and change saveiters to save the model at intermediate steps.\n",
        "\n",
        "NOTE: The training will run over several hours, usually over night or even over the weekend. Unfortunately, your google colab session will disconect after a few hours (limitations of free service). Saving the model at intermediate steps will reduce the amount of lost data and will allow you restart the training from the last saved point."
      ],
      "metadata": {
        "id": "Dhkq_W3LtMIv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#deeplabcut.train_network(path_config_file, shuffle=1, displayiters=100, saveiters=100)\n",
        "\n",
        "deeplabcut.pose_estimation_tensorflow.training.train_network(path_config_file, shuffle=1, trainingsetindex=0, max_snapshots_to_keep=5, displayiters=1000, saveiters=1000, maxiters=200000, gputouse=0, autotune=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Avthw2aWtO2D",
        "outputId": "a760043f-7588-4760-bb30-a0065c41cd05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Config:\n",
            "{'all_joints': [[0], [1], [2], [3]],\n",
            " 'all_joints_names': ['Snout', 'Head', 'Spine', 'TailBase'],\n",
            " 'alpha_r': 0.02,\n",
            " 'apply_prob': 0.5,\n",
            " 'batch_size': 1,\n",
            " 'contrast': {'clahe': True,\n",
            "              'claheratio': 0.1,\n",
            "              'histeq': True,\n",
            "              'histeqratio': 0.1},\n",
            " 'convolution': {'edge': False,\n",
            "                 'emboss': {'alpha': [0.0, 1.0], 'strength': [0.5, 1.5]},\n",
            "                 'embossratio': 0.1,\n",
            "                 'sharpen': False,\n",
            "                 'sharpenratio': 0.3},\n",
            " 'crop_pad': 0,\n",
            " 'cropratio': 0.4,\n",
            " 'dataset': 'training-datasets/iteration-1/UnaugmentedDataSet_ShoenfieldAug31/Shoenfield_Mena95shuffle1.mat',\n",
            " 'dataset_type': 'imgaug',\n",
            " 'decay_steps': 30000,\n",
            " 'deterministic': False,\n",
            " 'display_iters': 1000,\n",
            " 'fg_fraction': 0.25,\n",
            " 'global_scale': 0.8,\n",
            " 'init_weights': '/usr/local/lib/python3.10/dist-packages/deeplabcut/pose_estimation_tensorflow/models/pretrained/resnet_v1_101.ckpt',\n",
            " 'intermediate_supervision': False,\n",
            " 'intermediate_supervision_layer': 12,\n",
            " 'location_refinement': True,\n",
            " 'locref_huber_loss': True,\n",
            " 'locref_loss_weight': 0.05,\n",
            " 'locref_stdev': 7.2801,\n",
            " 'log_dir': 'log',\n",
            " 'lr_init': 0.0005,\n",
            " 'max_input_size': 1500,\n",
            " 'mean_pixel': [123.68, 116.779, 103.939],\n",
            " 'metadataset': 'training-datasets/iteration-1/UnaugmentedDataSet_ShoenfieldAug31/Documentation_data-Shoenfield_95shuffle1.pickle',\n",
            " 'min_input_size': 64,\n",
            " 'mirror': False,\n",
            " 'multi_stage': False,\n",
            " 'multi_step': [[0.005, 10000],\n",
            "                [0.02, 430000],\n",
            "                [0.002, 730000],\n",
            "                [0.001, 1030000]],\n",
            " 'net_type': 'resnet_101',\n",
            " 'num_joints': 4,\n",
            " 'optimizer': 'sgd',\n",
            " 'pairwise_huber_loss': False,\n",
            " 'pairwise_predict': False,\n",
            " 'partaffinityfield_predict': False,\n",
            " 'pos_dist_thresh': 17,\n",
            " 'project_path': '/content/drive/MyDrive/DLC_experimentos/Shoenfield-Mena-2023-08-31',\n",
            " 'regularize': False,\n",
            " 'rotation': 25,\n",
            " 'rotratio': 0.4,\n",
            " 'save_iters': 50000,\n",
            " 'scale_jitter_lo': 0.5,\n",
            " 'scale_jitter_up': 1.25,\n",
            " 'scoremap_dir': 'test',\n",
            " 'shuffle': True,\n",
            " 'snapshot_prefix': '/content/drive/MyDrive/DLC_experimentos/Shoenfield-Mena-2023-08-31/dlc-models/iteration-1/ShoenfieldAug31-trainset95shuffle1/train/snapshot',\n",
            " 'stride': 8.0,\n",
            " 'weigh_negatives': False,\n",
            " 'weigh_only_present_joints': False,\n",
            " 'weigh_part_predictions': False,\n",
            " 'weight_decay': 0.0001}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selecting single-animal trainer\n",
            "Batch Size is 1\n",
            "Loading ImageNet-pretrained resnet_101\n",
            "Max_iters overwritten as 200000\n",
            "Display_iters overwritten as 1000\n",
            "Save_iters overwritten as 1000\n",
            "Training parameter:\n",
            "{'stride': 8.0, 'weigh_part_predictions': False, 'weigh_negatives': False, 'fg_fraction': 0.25, 'mean_pixel': [123.68, 116.779, 103.939], 'shuffle': True, 'snapshot_prefix': '/content/drive/MyDrive/DLC_experimentos/Shoenfield-Mena-2023-08-31/dlc-models/iteration-1/ShoenfieldAug31-trainset95shuffle1/train/snapshot', 'log_dir': 'log', 'global_scale': 0.8, 'location_refinement': True, 'locref_stdev': 7.2801, 'locref_loss_weight': 0.05, 'locref_huber_loss': True, 'optimizer': 'sgd', 'intermediate_supervision': False, 'intermediate_supervision_layer': 12, 'regularize': False, 'weight_decay': 0.0001, 'crop_pad': 0, 'scoremap_dir': 'test', 'batch_size': 1, 'dataset_type': 'imgaug', 'deterministic': False, 'mirror': False, 'pairwise_huber_loss': False, 'weigh_only_present_joints': False, 'partaffinityfield_predict': False, 'pairwise_predict': False, 'all_joints': [[0], [1], [2], [3]], 'all_joints_names': ['Snout', 'Head', 'Spine', 'TailBase'], 'alpha_r': 0.02, 'apply_prob': 0.5, 'contrast': {'clahe': True, 'claheratio': 0.1, 'histeq': True, 'histeqratio': 0.1, 'gamma': False, 'sigmoid': False, 'log': False, 'linear': False}, 'convolution': {'edge': False, 'emboss': {'alpha': [0.0, 1.0], 'strength': [0.5, 1.5]}, 'embossratio': 0.1, 'sharpen': False, 'sharpenratio': 0.3}, 'cropratio': 0.4, 'dataset': 'training-datasets/iteration-1/UnaugmentedDataSet_ShoenfieldAug31/Shoenfield_Mena95shuffle1.mat', 'decay_steps': 30000, 'display_iters': 1000, 'init_weights': '/usr/local/lib/python3.10/dist-packages/deeplabcut/pose_estimation_tensorflow/models/pretrained/resnet_v1_101.ckpt', 'lr_init': 0.0005, 'max_input_size': 1500, 'metadataset': 'training-datasets/iteration-1/UnaugmentedDataSet_ShoenfieldAug31/Documentation_data-Shoenfield_95shuffle1.pickle', 'min_input_size': 64, 'multi_stage': False, 'multi_step': [[0.005, 10000], [0.02, 430000], [0.002, 730000], [0.001, 1030000]], 'net_type': 'resnet_101', 'num_joints': 4, 'pos_dist_thresh': 17, 'project_path': '/content/drive/MyDrive/DLC_experimentos/Shoenfield-Mena-2023-08-31', 'rotation': 25, 'rotratio': 0.4, 'save_iters': 50000, 'scale_jitter_lo': 0.5, 'scale_jitter_up': 1.25, 'covering': True, 'elastic_transform': True, 'motion_blur': True, 'motion_blur_params': {'k': 7, 'angle': (-90, 90)}}\n",
            "Starting training....\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1) Restart Training\n",
        "Typically, you want to train for 50k - 200k iterations. If your colab session terminated before that, run a second training session starting from the last saved iteration.\n",
        "\n",
        "Find the train subdirectory within the dlc-models directory and look for the latest snapshot. Open the pose_cfg.yaml file within the same folder and edit the parameter init_weights: '<full_path>-snapshot-10000' without any filetype ending.\n",
        "\n",
        "When you restart training will be resumed from the las saved pretrained model."
      ],
      "metadata": {
        "id": "o5bC48V1thlw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3) Evaluate your model\n"
      ],
      "metadata": {
        "id": "XrlhbW8utU0Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib notebook\n",
        "deeplabcut.evaluate_network(path_config_file,plotting=True)"
      ],
      "metadata": {
        "id": "98X7GAF2tfMn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "outputId": "227ee70e-19c3-4639-bfad-f39a3440f98c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/deeplabcut/pose_estimation_tensorflow/core/evaluate.py\u001b[0m in \u001b[0;36mevaluate_network\u001b[0;34m(config, Shuffles, trainingsetindex, plotting, show_errors, comparisonbodyparts, gputouse, rescale, modelprefix)\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# check if any where found?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 735\u001b[0;31m                     \u001b[0mSnapshots\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    736\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-0ddf06665c5e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'notebook'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdeeplabcut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_config_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mplotting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/deeplabcut/pose_estimation_tensorflow/core/evaluate.py\u001b[0m in \u001b[0;36mevaluate_network\u001b[0;34m(config, Shuffles, trainingsetindex, plotting, show_errors, comparisonbodyparts, gputouse, rescale, modelprefix)\u001b[0m\n\u001b[1;32m    735\u001b[0m                     \u001b[0mSnapshots\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 737\u001b[0;31m                     raise FileNotFoundError(\n\u001b[0m\u001b[1;32m    738\u001b[0m                         \u001b[0;34m\"Snapshots not found! It seems the dataset for shuffle %s and trainFraction %s is not trained.\\nPlease train it before evaluating.\\nUse the function 'train_network' to do so.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m                         \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainFraction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: Snapshots not found! It seems the dataset for shuffle 1 and trainFraction 0.95 is not trained.\nPlease train it before evaluating.\nUse the function 'train_network' to do so."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "deeplabcut.train_network(path_config_file, shuffle=1, displayiters=100, saveiters=100)"
      ],
      "metadata": {
        "id": "o2CquzV3tmS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5) Migrating your DLC project back to your local machine\n",
        "Download the DLC project directory from google drive to your local machine and change the project_directory in the config.yaml file back.\n",
        "\n",
        "Proceed with jupyter notebook partI."
      ],
      "metadata": {
        "id": "95Pi7NFDts8d"
      }
    }
  ]
}